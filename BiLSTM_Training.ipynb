{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets spacy gensim numpy torch scikit-learn tqdm matplotlib optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vShIrp_F7jAI",
        "outputId": "e7abf683-1b94-4e06-ee1e-97627cef9651",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PWtzzeQfpL-"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"sem_eval_2010_task_8\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entity_pos = {\"train\":[], \"test\":[], \"inference\":[]}\n",
        "embedding_dim=300\n",
        "entity_list = []\n",
        "target_classes = 19\n",
        "num_clusters = 5\n",
        "batch_size = 32\n",
        "max_num_clusters=15\n",
        "max_sentence_len=80"
      ],
      "metadata": {
        "id": "9xsQ68d9fz_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relation_names=[\n",
        "\"Cause-Effect(e1,e2)\",\n",
        "\"Cause-Effect(e2,e1)\",\n",
        "\"Component-Whole(e1,e2)\",\n",
        "\"Component-Whole(e2,e1)\",\n",
        "\"Content-Container(e1,e2)\",\n",
        "\"Content-Container(e2,e1)\",\n",
        "\"Entity-Destination(e1,e2)\",\n",
        "\"Entity-Destination(e2,e1)\",\n",
        "\"Entity-Origin(e1,e2)\",\n",
        "\"Entity-Origin(e2,e1)\",\n",
        "\"Instrument-Agency(e1,e2)\",\n",
        "\"Instrument-Agency(e2,e1)\",\n",
        "\"Member-Collection(e1,e2)\",\n",
        "\"Member-Collection(e2,e1)\",\n",
        "\"Message-Topic(e1,e2)\",\n",
        "\"Message-Topic(e2,e1)\",\n",
        "\"Product-Producer(e1,e2)\",\n",
        "\"Product-Producer(e2,e1)\",\n",
        "\"Other\"\n",
        "]"
      ],
      "metadata": {
        "id": "NtvbuDkh2ux_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "special_tokens = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    prefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\n",
        "    suffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.suffixes)\n",
        "    infix_re = spacy.util.compile_infix_regex(nlp.Defaults.infixes)\n",
        "\n",
        "    tokenizer = Tokenizer(nlp.vocab,\n",
        "                          prefix_search=prefix_re.search,\n",
        "                          suffix_search=suffix_re.search,\n",
        "                          infix_finditer=infix_re.finditer,\n",
        "                          token_match=None)\n",
        "\n",
        "    for token in special_tokens:\n",
        "        tokenizer.add_special_case(token, [{\"ORTH\": token}])\n",
        "\n",
        "    return tokenizer\n",
        "\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n",
        "\n",
        "def tokenize(text):\n",
        "    for token in special_tokens:\n",
        "        text = text.replace(token, f\" {token} \")  #Adding spaces to isolate markers\n",
        "\n",
        "    return [token.text.lower() for token in nlp(text)]"
      ],
      "metadata": {
        "id": "DmXfCgR7YbKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_freq = Counter(word for sentence in dataset[\"train\"][\"sentence\"] for word in tokenize(sentence))\n",
        "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "\n",
        "for i, (word, _) in enumerate(word_freq.most_common(), start=2):\n",
        "    word2idx[word] = i\n"
      ],
      "metadata": {
        "id": "TtZXd0XXiRs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(word2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoMwXXd4mTqP",
        "outputId": "46709a16-328f-49eb-8b67-3c4605835e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "\n",
        "def load_word2vec(word2idx):\n",
        "  word2vec = api.load(\"word2vec-google-news-300\")\n",
        "  vocab_size = len(word2idx)\n",
        "  embedding_matrix = np.random.uniform(-0.25, 0.25, (vocab_size, embedding_dim))\n",
        "\n",
        "  for word, idx in word2idx.items():\n",
        "      if word in word2vec:\n",
        "          embedding_matrix[idx] = word2vec[word]\n",
        "\n",
        "  return embedding_matrix"
      ],
      "metadata": {
        "id": "I19fGzZLvh4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "\n",
        "# Load embeddings from file\n",
        "def load_turian_embeddings(filepath):\n",
        "    word_vectors = {}\n",
        "    with gzip.open(filepath, 'rt', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split()\n",
        "            word = values[0]  # First column is the word\n",
        "            vector = np.array(values[1:], dtype=np.float32)  # Remaining columns are vector values\n",
        "            word_vectors[word] = vector\n",
        "    return word_vectors\n"
      ],
      "metadata": {
        "id": "jiG8s9sq3B78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_word_embeddings(word2idx, vecType):\n",
        "  if vecType == \"turian\":\n",
        "    embedding_file = \"embeddings-scaled.50.gz\"\n",
        "    word_embeddings = load_turian_embeddings(embedding_file)\n",
        "  elif  vecType == \"word2vec\":\n",
        "    word_embeddings = load_word2vec(word2idx)\n",
        "\n",
        "  return word_embeddings\n"
      ],
      "metadata": {
        "id": "oYuIp-mQ3ERT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings=load_word_embeddings(word2idx, \"word2vec\")"
      ],
      "metadata": {
        "id": "L7vwXkj3wIWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def encode_sentence(tokens, train_or_test, word2idx=word2idx, max_len=max_sentence_len):\n",
        "\n",
        "    #saving positions of entities in each sentence for later use\n",
        "    ei1_s = tokens.index(\"<e1>\")\n",
        "    ei1_e = tokens.index(\"</e1>\")\n",
        "    ei2_s = tokens.index(\"<e2>\")\n",
        "    ei2_e = tokens.index(\"</e2>\")\n",
        "    entity_pos[train_or_test].append(((ei1_s + 1, ei1_e),  (ei2_s + 1, ei2_e)))\n",
        "\n",
        "\n",
        "    #getting unique indices for each word based on vocab dictionary\n",
        "    indices = [word2idx.get(token, word2idx[\"<UNK>\"]) for token in tokens]\n",
        "    indices = indices[:max_len] + [word2idx[\"<PAD>\"]] * (max_len - len(indices))\n",
        "\n",
        "    return torch.tensor(indices, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "wvfakphFxUuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n"
      ],
      "metadata": {
        "id": "HiYIbASO1JaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.shape)\n",
        "print(test_dataset.shape)"
      ],
      "metadata": {
        "id": "YeFbRkFDxpnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf5428d-b8fd-46ca-c59e-88881f21ca16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 2)\n",
            "(2717, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def get_data_loader(data, train_or_test, shuffle, entity_hidden_states = None, entity_features = None):\n",
        "  encoded_sentences = [encode_sentence(tokenize(sentence), train_or_test) for sentence in data[\"sentence\"]]\n",
        "  labels = torch.tensor(data[\"relation\"], dtype=torch.long)\n",
        "  sentences_tensor = torch.stack(encoded_sentences)\n",
        "\n",
        "  dataset_args = [sentences_tensor, labels]\n",
        "\n",
        "  if entity_hidden_states is not None and entity_features is not None:\n",
        "    dataset_args.append(entity_hidden_states)\n",
        "    dataset_args.append(entity_features)\n",
        "\n",
        "  torch_dataset = TensorDataset(*dataset_args)\n",
        "  dataloader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "  return dataloader\n",
        "\n",
        "\n",
        "train_loader = get_data_loader(train_dataset, \"train\", False)\n",
        "test_loader = get_data_loader(test_dataset, \"test\", False)\n"
      ],
      "metadata": {
        "id": "zy1zT0x3xj3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RE_BiLSTM(nn.Module):\n",
        "  def __init__(self, embeddings, hidden_dim, vocab_size, num_layers, dropout_rate, output_dim=target_classes, embedding_dim=embedding_dim):\n",
        "    super(RE_BiLSTM, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2idx['<PAD>'])\n",
        "    if embeddings is not None:\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embeddings))\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
        "    self.embedding_dropout = nn.Dropout(dropout_rate)\n",
        "    self.output_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "    embedded = self.embedding_dropout(embedded)\n",
        "    lstm_out, _ = self.lstm(embedded)  # [batch_size, seq_len, hidden_dim*2]\n",
        "    lstm_out = self.output_dropout(lstm_out)\n",
        "\n",
        "    return lstm_out"
      ],
      "metadata": {
        "id": "_3lxufqR7tim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EntityAwareAttention(nn.Module):\n",
        "  def __init__(self, hidden_dim, dropout_rate, w_norm_threshold=0.5):\n",
        "    super(EntityAwareAttention, self).__init__()\n",
        "    self.tanh_hs = nn.Tanh()\n",
        "    self.w = nn.Parameter(torch.randn(hidden_dim * 2))\n",
        "    self.tanh_sent = nn.Tanh()\n",
        "    self.linear = nn.Linear(hidden_dim * 2, target_classes)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.w_norm_threshold=w_norm_threshold\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "    #hidden_states dim => batch_size, T, d\n",
        "    M = self.tanh_hs(hidden_states) #word_features dim => batch_size x T x d, where d = 2 * hidden_dim and T= max sentence length\n",
        "    alpha = torch.softmax(torch.matmul(M, self.w), dim=1)  #attention scores, batch_size x T dimensional\n",
        "    alpha = alpha.unsqueeze(1)  # Shape: [batch_size, 1, T]\n",
        "    r = torch.bmm(alpha, hidden_states).squeeze(1)  #batch_size x d dimensional\n",
        "    h_star = self.tanh_sent(r) #batch_size x d dimensional\n",
        "    h_star = self.dropout(h_star)\n",
        "    preds = self.linear(h_star) #batch_size x target_classes\n",
        "\n",
        "    return preds\n",
        "\n"
      ],
      "metadata": {
        "id": "qr7K67jS4MSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RE_Model(nn.Module):\n",
        "  def __init__(self, embeddings, hidden_dim, vocab_size, lstm_layers,\n",
        "               dropout_rate, output_dim=target_classes, embedding_dim=embedding_dim,  use_entity_attention=True):\n",
        "    super(RE_Model, self).__init__()\n",
        "    self.lstm = RE_BiLSTM(embeddings, hidden_dim, vocab_size, num_layers=lstm_layers, dropout_rate=dropout_rate)\n",
        "    self.WH = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n",
        "    self.WE = nn.Linear((hidden_dim * 2) * 4, hidden_dim * 2)\n",
        "    self.ent_att = EntityAwareAttention(hidden_dim, dropout_rate)\n",
        "    self.use_entity_attention = use_entity_attention\n",
        "    self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, x, entity_hidden_states, entity_types):\n",
        "    lstm_out = self.lstm(x)\n",
        "\n",
        "    if self.use_entity_attention:\n",
        "      entity_hidden_states = torch.cat((entity_hidden_states[:, 0, :], entity_hidden_states[:, 1, :]), dim=-1)\n",
        "      entity_types = torch.cat((entity_types[:, 0, :], entity_types[:, 1, :]), dim=-1)\n",
        "      entity_hidden_states.unsqueeze(1)\n",
        "      entity_types.unsqueeze(1)\n",
        "\n",
        "      #dim of both tensors above => batch_size, 1, (hidden_dim * 2) * 2\n",
        "\n",
        "      entity_features = torch.cat([entity_hidden_states, entity_types], dim = -1) #dim =>[batch_size, 1, (hidden_dim * 2) * 2]\n",
        "\n",
        "      entity_features = self.dropout(entity_features)\n",
        "      e = self.layer_norm(self.WE(entity_features))\n",
        "      l = self.WH(lstm_out)\n",
        "      e = e.unsqueeze(1)\n",
        "\n",
        "      word_features = e + l\n",
        "      preds = self.ent_att(word_features)\n",
        "    else:\n",
        "      preds = self.ent_att(lstm_out)\n",
        "\n",
        "\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "TlGXU2dq4RBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EntityEncoderBiLSTM(nn.Module):\n",
        "  def __init__(self, embeddings, hidden_dim, vocab_size, num_layers, dropout_rate, output_dim=target_classes, embedding_dim=embedding_dim):\n",
        "    super(EntityEncoderBiLSTM, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2idx['<PAD>'])\n",
        "    if embeddings is not None:\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embeddings))\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=True, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
        "    self.embedding_dropout = nn.Dropout(dropout_rate)\n",
        "    self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.lstm_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    embedded = self.embedding_dropout(embedded)\n",
        "    lstm_out, _ = self.lstm(embedded)\n",
        "    lstm_out = self.lstm_dropout(lstm_out)\n",
        "    pooled = torch.mean(lstm_out, dim=1)\n",
        "    output = self.dropout(pooled)\n",
        "    output = self.fc(output)\n",
        "    return output, lstm_out\n",
        "\n"
      ],
      "metadata": {
        "id": "xMcFqlBb4SbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hs_mean(sent_hidden_states, ep):\n",
        "  start = ep[0]\n",
        "  end = ep[1]\n",
        "  if start == end:\n",
        "    return sent_hidden_states[start]\n",
        "  else:\n",
        "    return torch.sum(sent_hidden_states[start:end], dim=0) / (end - start)"
      ],
      "metadata": {
        "id": "8mE_wtTec4hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entities_hs_from_sentence(lstm_out, pos_index, train_or_test):\n",
        "\n",
        "  en_hs_list = []\n",
        "  for sent_hid_states in (lstm_out):\n",
        "    (e1p, e2p) = entity_pos[train_or_test][pos_index]\n",
        "    h1 = get_hs_mean(sent_hid_states, e1p)\n",
        "    h2 = get_hs_mean(sent_hid_states, e2p)\n",
        "    en_pair = torch.stack([h1, h2]) #dim => 2 x hidden_dim * 2\n",
        "    en_hs_list.append(en_pair)\n",
        "    pos_index += 1\n",
        "\n",
        "\n",
        "  return torch.stack(en_hs_list), pos_index #dim => batch_size x 2 x hidden_dim * 2"
      ],
      "metadata": {
        "id": "PBH-XQDr4afe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entity_hidden_states(model, loader, train_or_test):\n",
        "\n",
        "  #Getting the hidden states of entities based on position in sentence\n",
        "\n",
        "  model.eval()\n",
        "  en_hs_tensors_list = []\n",
        "  with torch.no_grad():\n",
        "      pos_index = 0\n",
        "      for x_batch, y_batch in loader:\n",
        "        _, lstm_out = model(x_batch)\n",
        "        en_hs_list, pos_index = get_entities_hs_from_sentence(lstm_out, pos_index, train_or_test)\n",
        "        en_hs_tensors_list.append(en_hs_list)\n",
        "\n",
        "      return torch.cat(en_hs_tensors_list, dim=0)  #dim => batch_size, 2, hidden_dim * 2\n"
      ],
      "metadata": {
        "id": "KbKcrkuT4gZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_encoder_model(model, data_loader, train_or_test):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    pos_index = 0\n",
        "    load_hs = False\n",
        "    hs_list = []\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in data_loader:\n",
        "          outputs, lstm_out = model(x_batch)\n",
        "          predictions = torch.argmax(outputs, dim=1)\n",
        "          correct += (predictions == y_batch).sum().item()\n",
        "          total += y_batch.size(0)\n",
        "\n",
        "          all_predictions.extend(predictions.cpu().numpy())\n",
        "          all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    acc = correct / total * 100\n",
        "    macro_f1 = f1_score(all_labels, all_predictions, average=\"macro\")\n",
        "    print(f'{train_or_test} Accuracy: {acc}%')\n",
        "    print(f\"{train_or_test} Macro F1-score: {macro_f1:.4f}\")\n",
        "\n",
        "    return acc\n",
        "\n"
      ],
      "metadata": {
        "id": "MEZcTAb941aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_RE_model(model, data_loader, train_or_test):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    pos_index = 0\n",
        "    load_hs = False\n",
        "    hs_list = []\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch, entity_hidden_states, entity_type_features in data_loader:\n",
        "          outputs = model(x_batch, entity_hidden_states, entity_type_features)\n",
        "          predictions = torch.argmax(outputs, dim=1)\n",
        "          correct += (predictions == y_batch).sum().item()\n",
        "          total += y_batch.size(0)\n",
        "          all_predictions.extend(predictions.cpu().numpy())\n",
        "          all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "\n",
        "    acc = correct / total * 100\n",
        "    macro_f1 = f1_score(all_labels, all_predictions, average=\"macro\")\n",
        "    print(f'{train_or_test} Accuracy: {acc}%')\n",
        "    print(f\"{train_or_test} Macro F1-score: {macro_f1:.4f}\")\n",
        "\n",
        "    return acc\n",
        "\n"
      ],
      "metadata": {
        "id": "lI_Qzkf744B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_RE_wo_types_model(model, data_loader, train_or_test):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    pos_index = 0\n",
        "    load_hs = False\n",
        "    hs_list = []\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in data_loader:\n",
        "          outputs = model(x_batch, None, None)\n",
        "          predictions = torch.argmax(outputs, dim=1)\n",
        "          correct += (predictions == y_batch).sum().item()\n",
        "          total += y_batch.size(0)\n",
        "          all_predictions.extend(predictions.cpu().numpy())\n",
        "          all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "\n",
        "    acc = correct / total * 100\n",
        "    macro_f1 = f1_score(all_labels, all_predictions, average=\"macro\")\n",
        "    print(f'{train_or_test} Accuracy: {acc}%')\n",
        "    print(f\"{train_or_test} Macro F1-score: {macro_f1:.4f}\")\n",
        "\n",
        "    return acc\n",
        "\n"
      ],
      "metadata": {
        "id": "p-wigsAnJdwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_RE_wo_types_model(model, train_loader, optimizer, criterion, epochs=10, lr=0.001):\n",
        "    prev_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(x_batch,  None, None)\n",
        "          loss = criterion(outputs, y_batch)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}')\n",
        "        train_acc = 0\n",
        "        prev_acc = train_acc\n",
        "        train_acc = evaluate_RE_wo_types_model(model, train_loader, \"train\")\n",
        "\n"
      ],
      "metadata": {
        "id": "bC4pHCAc45Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_RE_model(model, train_loader, optimizer, criterion, epochs=10, lr=0.001):\n",
        "    prev_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch, hidden_states, entity_type_features in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(x_batch,  hidden_states.detach(), entity_type_features.detach())\n",
        "          loss = criterion(outputs, y_batch)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}')\n",
        "        train_acc = 0\n",
        "        prev_acc = train_acc\n",
        "        train_acc = evaluate_RE_model(model, train_loader, \"train\")\n",
        "\n"
      ],
      "metadata": {
        "id": "K5UiRME8I_fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_encoder_model(model, train_loader, optimizer, criterion, epochs=10):\n",
        "\n",
        "    prev_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
        "            optimizer.zero_grad()\n",
        "            outputs, lstm_out = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}')\n",
        "        train_acc = 0\n",
        "        prev_acc = train_acc\n",
        "        train_acc = evaluate_encoder_model(model, train_loader, \"train\")\n",
        "\n"
      ],
      "metadata": {
        "id": "eTrYvPh246qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 256\n",
        "dropout_rate = 0.44586702274269596\n",
        "num_layers = 2\n",
        "weight_decay=1e-05\n",
        "epochs= 25\n",
        "learning_rate=1\n",
        "\n",
        "entity_lstm_model = EntityEncoderBiLSTM(embeddings=word_embeddings, hidden_dim=hidden_dim, vocab_size=len(word2idx), num_layers=num_layers,\n",
        "                       dropout_rate=dropout_rate, output_dim=target_classes)\n",
        "optimizer = optim.Adadelta(entity_lstm_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_encoder_model(entity_lstm_model, train_loader, optimizer, loss_fn, epochs=epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLgFFEDH7g9r",
        "outputId": "27511a46-cbbe-44da-d2b9-59977d4d2b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 250/250 [00:43<00:00,  5.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 2.6611\n",
            "train Accuracy: 17.575%\n",
            "train Macro F1-score: 0.0157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 250/250 [00:43<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 2.5766\n",
            "train Accuracy: 17.5625%\n",
            "train Macro F1-score: 0.0168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 250/250 [00:43<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 2.4614\n",
            "train Accuracy: 18.0375%\n",
            "train Macro F1-score: 0.0301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 250/250 [00:43<00:00,  5.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 2.2853\n",
            "train Accuracy: 23.6125%\n",
            "train Macro F1-score: 0.0549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 250/250 [00:43<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 2.0627\n",
            "train Accuracy: 25.637500000000003%\n",
            "train Macro F1-score: 0.0896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 250/250 [00:43<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss: 1.8288\n",
            "train Accuracy: 40.0%\n",
            "train Macro F1-score: 0.2455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 250/250 [00:43<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss: 1.5829\n",
            "train Accuracy: 44.3375%\n",
            "train Macro F1-score: 0.2889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 250/250 [00:43<00:00,  5.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss: 1.4007\n",
            "train Accuracy: 55.012499999999996%\n",
            "train Macro F1-score: 0.4527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 250/250 [00:43<00:00,  5.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss: 1.2360\n",
            "train Accuracy: 66.95%\n",
            "train Macro F1-score: 0.5571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 250/250 [00:43<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 1.0869\n",
            "train Accuracy: 70.8%\n",
            "train Macro F1-score: 0.5834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 250/250 [00:43<00:00,  5.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Loss: 0.9633\n",
            "train Accuracy: 74.0125%\n",
            "train Macro F1-score: 0.6124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 250/250 [00:43<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Loss: 0.8614\n",
            "train Accuracy: 76.7%\n",
            "train Macro F1-score: 0.6475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 250/250 [00:43<00:00,  5.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Loss: 0.7600\n",
            "train Accuracy: 76.825%\n",
            "train Macro F1-score: 0.6664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 250/250 [00:43<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Loss: 0.6954\n",
            "train Accuracy: 78.9375%\n",
            "train Macro F1-score: 0.6967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 250/250 [00:43<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Loss: 0.6301\n",
            "train Accuracy: 84.325%\n",
            "train Macro F1-score: 0.7637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 250/250 [00:43<00:00,  5.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Loss: 0.5805\n",
            "train Accuracy: 85.82499999999999%\n",
            "train Macro F1-score: 0.7853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 250/250 [00:43<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Loss: 0.5203\n",
            "train Accuracy: 87.2125%\n",
            "train Macro F1-score: 0.8068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 250/250 [00:44<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Loss: 0.4692\n",
            "train Accuracy: 89.6375%\n",
            "train Macro F1-score: 0.8377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 250/250 [00:43<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Loss: 0.4262\n",
            "train Accuracy: 90.5875%\n",
            "train Macro F1-score: 0.8472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 250/250 [00:43<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Loss: 0.3911\n",
            "train Accuracy: 92.6875%\n",
            "train Macro F1-score: 0.8700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 250/250 [00:42<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 Loss: 0.3465\n",
            "train Accuracy: 92.825%\n",
            "train Macro F1-score: 0.8761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 250/250 [00:44<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Loss: 0.3259\n",
            "train Accuracy: 91.9625%\n",
            "train Macro F1-score: 0.8628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 250/250 [00:43<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 Loss: 0.2967\n",
            "train Accuracy: 94.2625%\n",
            "train Macro F1-score: 0.8897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 250/250 [00:43<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 Loss: 0.2637\n",
            "train Accuracy: 95.6%\n",
            "train Macro F1-score: 0.9025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 250/250 [00:43<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 Loss: 0.2468\n",
            "train Accuracy: 95.78750000000001%\n",
            "train Macro F1-score: 0.9068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_encoder_model(entity_lstm_model, test_loader, \"test\")"
      ],
      "metadata": {
        "id": "vmArJc7ISICa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55fe77a-7577-4ce8-824d-cf3a40f99d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Accuracy: 70.26131762973868%\n",
            "test Macro F1-score: 0.6631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70.26131762973868"
            ]
          },
          "metadata": {},
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(entity_lstm_model.state_dict(), \"encoder_weights.pth\")"
      ],
      "metadata": {
        "id": "c3hOlA5YSL5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_entity_hidden_states = get_entity_hidden_states(entity_lstm_model, train_loader, \"train\")\n",
        "test_entity_hidden_states = get_entity_hidden_states(entity_lstm_model, test_loader, \"test\")"
      ],
      "metadata": {
        "id": "msHcu47oSNsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_entity_hidden_states\", train_entity_hidden_states.shape)\n",
        "print(\"test_entity_hidden_states\", test_entity_hidden_states.shape)"
      ],
      "metadata": {
        "id": "5xQ4qaIBSPiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdae3619-5cb7-48f3-d9fb-787f5607c7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_entity_hidden_states torch.Size([8000, 2, 512])\n",
            "test_entity_hidden_states torch.Size([2717, 2, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entity_type_features(hidden_states, clustering_type, model, hs_array=None):\n",
        "\n",
        "  if hs_array is None:\n",
        "    hs_array = np.array([e for tup in hidden_states for e in tup])\n",
        "\n",
        "  if clustering_type == 'KMeans':\n",
        "    entity_types = model.predict(hs_array)\n",
        "  elif clustering_type == 'GaussianMixture':\n",
        "    soft_labels = model.predict_proba(hs_array)\n",
        "    component_indices = np.arange(num_clusters)\n",
        "    entity_types = np.dot(soft_labels, component_indices)  # (number of entities,) weighted assignment\n",
        "\n",
        "\n",
        "  entity_type_embeddings = nn.Embedding(num_clusters, embedding_dim=hidden_dim*2)\n",
        "  entity_type_features = entity_type_embeddings(torch.tensor(entity_types, dtype=torch.long)) #shape = (num_of_entities, hidden_dim * 2)\n",
        "\n",
        "  num_sentences = entity_type_features.shape[0] // 2\n",
        "  entity_type_features = entity_type_features.view(num_sentences, 2, -1)  #dim => num_setences, num_entities per sentence (=2), hidden_dim * 2\n",
        "\n",
        "  return entity_type_features\n"
      ],
      "metadata": {
        "id": "5VHQR1tpSSMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#collect all entities in np array for clustering\n",
        "entity_hs_array = np.array([e for tup in train_entity_hidden_states for e in tup])"
      ],
      "metadata": {
        "id": "0njMYXPWSZgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention LSTM (without Entity Awareness)"
      ],
      "metadata": {
        "id": "NgnlWGV4UESp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get new dataloaders\n",
        "\n",
        "train_loader = get_data_loader(train_dataset, \"train\", False, entity_hidden_states=None, entity_features=None)\n",
        "test_loader = get_data_loader(test_dataset, \"test\", False, entity_hidden_states=None, entity_features=None)"
      ],
      "metadata": {
        "id": "uX2uo8--IQA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hidden_dim = 256\n",
        "dropout_rate = 0.44586702274269596\n",
        "learning_rate = 1\n",
        "num_layers = 1\n",
        "weight_decay= 1e-05\n",
        "epochs= 15\n",
        "re_model = RE_Model(embeddings=word_embeddings, hidden_dim=hidden_dim, vocab_size=len(word2idx), lstm_layers=num_layers,\n",
        "                      dropout_rate=dropout_rate, use_entity_attention=False)\n",
        "\n",
        "optimizer = optim.Adadelta(re_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_RE_wo_types_model(re_model, train_loader, optimizer, loss_fn, epochs=epochs, lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "D5ibUGHQTzNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc97612-157c-4cda-af77-aac702ef8afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 250/250 [00:25<00:00,  9.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 2.6852\n",
            "train Accuracy: 17.625%\n",
            "train Macro F1-score: 0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 250/250 [00:24<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 2.6410\n",
            "train Accuracy: 17.625%\n",
            "train Macro F1-score: 0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 250/250 [00:25<00:00,  9.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 2.1744\n",
            "train Accuracy: 39.0125%\n",
            "train Macro F1-score: 0.2379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 250/250 [00:25<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 1.5234\n",
            "train Accuracy: 58.225%\n",
            "train Macro F1-score: 0.4902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 250/250 [00:26<00:00,  9.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 1.2272\n",
            "train Accuracy: 66.75%\n",
            "train Macro F1-score: 0.5660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 250/250 [00:26<00:00,  9.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss: 1.0729\n",
            "train Accuracy: 72.425%\n",
            "train Macro F1-score: 0.6256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 250/250 [00:29<00:00,  8.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss: 0.9531\n",
            "train Accuracy: 76.075%\n",
            "train Macro F1-score: 0.6946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 250/250 [00:28<00:00,  8.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss: 0.8324\n",
            "train Accuracy: 80.825%\n",
            "train Macro F1-score: 0.7531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 250/250 [00:27<00:00,  9.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss: 0.7495\n",
            "train Accuracy: 82.475%\n",
            "train Macro F1-score: 0.7791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 250/250 [00:27<00:00,  9.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 0.6775\n",
            "train Accuracy: 85.6625%\n",
            "train Macro F1-score: 0.8077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 250/250 [00:28<00:00,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Loss: 0.6178\n",
            "train Accuracy: 86.05000000000001%\n",
            "train Macro F1-score: 0.8150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 250/250 [00:29<00:00,  8.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Loss: 0.5603\n",
            "train Accuracy: 89.05%\n",
            "train Macro F1-score: 0.8433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 250/250 [00:30<00:00,  8.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Loss: 0.4993\n",
            "train Accuracy: 91.525%\n",
            "train Macro F1-score: 0.8650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 250/250 [00:30<00:00,  8.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Loss: 0.4497\n",
            "train Accuracy: 92.225%\n",
            "train Macro F1-score: 0.8733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 250/250 [00:29<00:00,  8.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Loss: 0.4076\n",
            "train Accuracy: 94.1%\n",
            "train Macro F1-score: 0.8881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_RE_wo_types_model(re_model, test_loader, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQu1uqKtMBnU",
        "outputId": "bdeedd8a-d587-48da-8abf-e1d88b71111e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Accuracy: 74.97239602502759%\n",
            "test Macro F1-score: 0.7223\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74.97239602502759"
            ]
          },
          "metadata": {},
          "execution_count": 420
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(re_model.state_dict(), \"RE_without_entities_model_weights.pth\")"
      ],
      "metadata": {
        "id": "a2jpMlJwUjpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention Mechanism with Entity Awareness"
      ],
      "metadata": {
        "id": "gzwdpReaUSi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using KMeans for Entity Typing"
      ],
      "metadata": {
        "id": "D8L3HCszGNw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(entity_hs_array)"
      ],
      "metadata": {
        "id": "JQRwcCxkTLJa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "ff185c81-98a7-4c76-e623-6d3fdd7a21c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=5, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-5 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-5 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-5 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-5 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-5 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KMeans</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=5, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "train_entity_type_features = get_entity_type_features(train_entity_hidden_states, \"KMeans\", kmeans, hs_array=entity_hs_array)\n",
        "test_entity_type_features = get_entity_type_features(test_entity_hidden_states, \"KMeans\", kmeans)"
      ],
      "metadata": {
        "id": "8oT_H4ZKTO3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get new dataloaders, which include entity hidden states and type features\n",
        "\n",
        "train_loader = get_data_loader(train_dataset, \"train\", False, entity_hidden_states=train_entity_hidden_states, entity_features=train_entity_type_features)\n",
        "test_loader = get_data_loader(test_dataset, \"test\", False, entity_hidden_states=test_entity_hidden_states, entity_features=test_entity_type_features)"
      ],
      "metadata": {
        "id": "87n7Vlk5TtZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 256\n",
        "dropout_rate = 0.5\n",
        "num_layers = 1\n",
        "weight_decay = 5e-5\n",
        "epochs = 15\n",
        "learning_rate=5e-5\n",
        "\n",
        "re_model = RE_Model(embeddings=word_embeddings, hidden_dim=hidden_dim, vocab_size=len(word2idx), lstm_layers=num_layers,\n",
        "                      dropout_rate=dropout_rate, use_entity_attention=True)\n",
        "\n",
        "optimizer = optim.AdamW(re_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_RE_model(re_model, train_loader, optimizer, loss_fn, epochs=epochs, lr=learning_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPtgfWDuG97A",
        "outputId": "1451c814-12db-4c26-b23f-0aebb2470de5"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 250/250 [00:51<00:00,  4.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 0.4055\n",
            "train Accuracy: 92.475%\n",
            "train Macro F1-score: 0.8716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 250/250 [00:50<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 0.2049\n",
            "train Accuracy: 94.6375%\n",
            "train Macro F1-score: 0.8882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 250/250 [00:50<00:00,  4.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 0.1850\n",
            "train Accuracy: 94.1875%\n",
            "train Macro F1-score: 0.8744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 250/250 [00:50<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 0.1883\n",
            "train Accuracy: 95.375%\n",
            "train Macro F1-score: 0.8971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 250/250 [00:50<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 0.1699\n",
            "train Accuracy: 95.92500000000001%\n",
            "train Macro F1-score: 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 250/250 [00:50<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss: 0.1661\n",
            "train Accuracy: 95.6875%\n",
            "train Macro F1-score: 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 250/250 [00:51<00:00,  4.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss: 0.1587\n",
            "train Accuracy: 96.1%\n",
            "train Macro F1-score: 0.9092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 250/250 [00:50<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss: 0.1584\n",
            "train Accuracy: 95.5875%\n",
            "train Macro F1-score: 0.9019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 250/250 [00:50<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss: 0.1584\n",
            "train Accuracy: 96.0125%\n",
            "train Macro F1-score: 0.9069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 250/250 [00:50<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 0.1531\n",
            "train Accuracy: 96.1125%\n",
            "train Macro F1-score: 0.9067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_RE_model(re_model, test_loader, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGCjum_rHss-",
        "outputId": "903cb06d-8455-4bc8-e88f-08cb95fbcd69"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Accuracy: 68.49466323150534%\n",
            "test Macro F1-score: 0.6451\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68.49466323150534"
            ]
          },
          "metadata": {},
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(re_model.state_dict(), \"RE_with_kmeans_entities_model_weights.pth\")"
      ],
      "metadata": {
        "id": "ShUI8l59HADa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GMM for Entity Typing"
      ],
      "metadata": {
        "id": "PPRbHptgGXry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "import numpy as np\n",
        "\n",
        "gmm = GaussianMixture(n_components=num_clusters, covariance_type='tied', random_state=42)\n",
        "gmm.fit(entity_hs_array)"
      ],
      "metadata": {
        "id": "MZLKsLYBTMw3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "f529d723-967c-4be3-813b-d5bfdb387d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianMixture(covariance_type='tied', n_components=5, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianMixture(covariance_type=&#x27;tied&#x27;, n_components=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianMixture</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.mixture.GaussianMixture.html\">?<span>Documentation for GaussianMixture</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianMixture(covariance_type=&#x27;tied&#x27;, n_components=5, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_entity_type_features = get_entity_type_features(train_entity_hidden_states, \"GaussianMixture\", gmm, hs_array=entity_hs_array)\n",
        "test_entity_type_features = get_entity_type_features(test_entity_hidden_states, \"GaussianMixture\", gmm)"
      ],
      "metadata": {
        "id": "L8DPDCDMGW4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get new dataloaders, which include entity hidden states and type features\n",
        "\n",
        "train_loader = get_data_loader(train_dataset, \"train\", False, entity_hidden_states=train_entity_hidden_states, entity_features=train_entity_type_features)\n",
        "test_loader = get_data_loader(test_dataset, \"test\", False, entity_hidden_states=test_entity_hidden_states, entity_features=test_entity_type_features)"
      ],
      "metadata": {
        "id": "Q1oaAkZUG68I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 256\n",
        "dropout_rate = 0.5\n",
        "num_layers = 1\n",
        "weight_decay = 5e-5\n",
        "epochs = 15\n",
        "learning_rate=5e-5\n",
        "\n",
        "re_model = RE_Model(embeddings=word_embeddings, hidden_dim=hidden_dim, vocab_size=len(word2idx), lstm_layers=num_layers,\n",
        "                      dropout_rate=dropout_rate, use_entity_attention=True)\n",
        "\n",
        "optimizer = optim.AdamW(re_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_RE_model(re_model, train_loader, optimizer, loss_fn, epochs=epochs, lr=learning_rate)"
      ],
      "metadata": {
        "id": "8uyAAZ2pT0nN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d7a733-472e-41a9-bc86-6dae7b223a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 250/250 [00:21<00:00, 11.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.0249\n",
            "train Accuracy: 90.47500000000001%\n",
            "train Macro F1-score: 0.7823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 250/250 [00:21<00:00, 11.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 0.4005\n",
            "train Accuracy: 93.7625%\n",
            "train Macro F1-score: 0.8657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 250/250 [00:21<00:00, 11.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 0.2800\n",
            "train Accuracy: 95.0375%\n",
            "train Macro F1-score: 0.8920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 250/250 [00:23<00:00, 10.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 0.2276\n",
            "train Accuracy: 95.575%\n",
            "train Macro F1-score: 0.8997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 250/250 [00:23<00:00, 10.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 0.1965\n",
            "train Accuracy: 95.92500000000001%\n",
            "train Macro F1-score: 0.9035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 250/250 [00:23<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss: 0.1859\n",
            "train Accuracy: 96.1%\n",
            "train Macro F1-score: 0.9048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 250/250 [00:23<00:00, 10.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss: 0.1696\n",
            "train Accuracy: 96.15%\n",
            "train Macro F1-score: 0.9060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 250/250 [00:23<00:00, 10.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss: 0.1608\n",
            "train Accuracy: 96.275%\n",
            "train Macro F1-score: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 250/250 [00:23<00:00, 10.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss: 0.1554\n",
            "train Accuracy: 96.46249999999999%\n",
            "train Macro F1-score: 0.9094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 250/250 [00:23<00:00, 10.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 0.1460\n",
            "train Accuracy: 96.26249999999999%\n",
            "train Macro F1-score: 0.9053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 250/250 [00:23<00:00, 10.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Loss: 0.1391\n",
            "train Accuracy: 96.7%\n",
            "train Macro F1-score: 0.9124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 250/250 [00:23<00:00, 10.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Loss: 0.1397\n",
            "train Accuracy: 96.89999999999999%\n",
            "train Macro F1-score: 0.9139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 250/250 [00:23<00:00, 10.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Loss: 0.1297\n",
            "train Accuracy: 96.89999999999999%\n",
            "train Macro F1-score: 0.9147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 250/250 [00:23<00:00, 10.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Loss: 0.1264\n",
            "train Accuracy: 96.8625%\n",
            "train Macro F1-score: 0.9140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 250/250 [00:23<00:00, 10.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Loss: 0.1258\n",
            "train Accuracy: 96.75%\n",
            "train Macro F1-score: 0.9130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_RE_model(re_model, test_loader, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNeZVzVpHyuD",
        "outputId": "d9eb2019-ee7e-44b6-dcab-3bc334c1bb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Accuracy: 64.26205373573795%\n",
            "test Macro F1-score: 0.6205\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64.26205373573795"
            ]
          },
          "metadata": {},
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(re_model.state_dict(), \"RE_with_gmm_entities_model_weights.pth\")"
      ],
      "metadata": {
        "id": "sclX2-iIUnqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(gmm, \"gmm_model.pkl\")\n",
        "joblib.dump(kmeans, \"kmeans_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRgvpjOMZ_sG",
        "outputId": "c99a15f2-4b48-4418-f3f6-c0d43b685a7a"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gmm_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 453
        }
      ]
    }
  ]
}